# MS SQL Data Cleaning Project

This project demonstrates my skills in **data cleaning using Microsoft SQL Server**, a crucial step in preparing data for analysis or reporting. The dataset used contains over 2,300 records of company layoffs with various attributes.

# Project Overview

The goal of this project was to clean and prepare raw layoff data stored in an SQL table by applying best practices for data wrangling and quality assurance.

# Tasks Performed:

- **Removing Duplicates**: Identified and deleted exact and partial duplicate records.
- **Standardizing Data**: Ensured consistent formatting across key fields (like names and locations).
- **Handling NULL & Blank Values**: Replaced missing values where appropriate or removed incomplete rows.
- **Dropping Unnecessary Rows & Columns**: Removed data that was irrelevant or redundant for analysis.

# Files Included

- `Data Excel sheet`
- `SQL Queries`

# Key Learnings

- How to write efficient SQL queries for cleaning large datasets
- Using `CTEs`, `ROW_NUMBER()`, `CASE`, and other SQL constructs for data wrangling
- Importance of clean, well-structured data in downstream analysis

## ðŸ”— Usage

Clone or download the repo to explore how I approached cleaning this dataset. You can run the SQL scripts in SSMS or any SQL environment compatible with Microsoft SQL Server.


**Note:** This project is for learning and portfolio purposes. No sensitive or proprietary data is included.
